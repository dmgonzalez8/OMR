{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54478133-a803-4297-96db-2ce4e37e66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "from shapely.geometry import Polygon, LineString, Point\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torch.optim import SGD, Adam, Adadelta\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fb7df7-c953-4196-aed7-6b23c6120305",
   "metadata": {},
   "source": [
    "### load json annotation dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d8b474-7cd3-4ee5-ae9b-c2bb64b1a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data into a dictionary\n",
    "with open('./data/ds2_dense/deepscores_train.json') as file:\n",
    "    data1 = json.load(file)\n",
    "with open('./data/ds2_dense/deepscores_test.json') as file:\n",
    "    data2 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2dbc3a6e-d40e-48d1-85df-d45a0599839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pandas\n",
    "# train_labels = pd.DataFrame( data1['categories']).T\n",
    "train_images = pd.DataFrame( data1['images'])\n",
    "train_obboxs = pd.DataFrame( data1['annotations']).T\n",
    "# test_labels = pd.DataFrame( data2['categories']).T\n",
    "test_images = pd.DataFrame( data2['images'])\n",
    "test_obboxs = pd.DataFrame( data2['annotations']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99470ab5-38d9-4d5a-84ab-c0de5588f0a7",
   "metadata": {},
   "source": [
    "### prepare the labels - I adjusted the json slightly so use `new_labels.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "53708547-3aca-4cf6-8f25-36a26e882321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>brace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ledgerLine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>repeatDot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>segno</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        name\n",
       "0      1       brace\n",
       "1      2  ledgerLine\n",
       "2      3   repeatDot\n",
       "3      4       segno"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the new mapping\n",
    "train_labels = pd.read_csv('new_labels.csv')\n",
    "# make a df of the unique labels with their names\n",
    "unique_labels = train_labels[['label', 'name']]\n",
    "unique_labels = unique_labels.drop_duplicates(subset=['label'])\n",
    "unique_labels = unique_labels.sort_values(by=['label']).reset_index(drop=True)\n",
    "unique_labels.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a5fb0-fb57-498c-953d-0170becc754d",
   "metadata": {},
   "source": [
    "### prepare the image/annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ded83a7-c57e-4b8f-93c7-20299d52683e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>ann_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>lg-75827152-aug-lilyjazz-.png</td>\n",
       "      <td>1960</td>\n",
       "      <td>2772</td>\n",
       "      <td>[160131, 160132, 160133, 160134, 160135, 16013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>lg-210359136-aug-lilyjazz--page-14.png</td>\n",
       "      <td>1960</td>\n",
       "      <td>2772</td>\n",
       "      <td>[503778, 503779, 503780, 503781, 503782, 50378...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>lg-366136986510816260-aug-gutenberg1939-.png</td>\n",
       "      <td>1960</td>\n",
       "      <td>2772</td>\n",
       "      <td>[769765, 769766, 769767, 769768, 769769, 76977...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   img_id                                      filename  width  height  \\\n",
       "0       1                 lg-75827152-aug-lilyjazz-.png   1960    2772   \n",
       "1       5        lg-210359136-aug-lilyjazz--page-14.png   1960    2772   \n",
       "2       6  lg-366136986510816260-aug-gutenberg1939-.png   1960    2772   \n",
       "\n",
       "                                             ann_ids  \n",
       "0  [160131, 160132, 160133, 160134, 160135, 16013...  \n",
       "1  [503778, 503779, 503780, 503781, 503782, 50378...  \n",
       "2  [769765, 769766, 769767, 769768, 769769, 76977...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.rename(columns={'id': 'img_id'}, inplace=True)\n",
    "test_images.rename(columns={'id': 'img_id'}, inplace=True)\n",
    "test_images.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "571ea033-d991-4ff1-a0d7-93ebc16d75b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann_id</th>\n",
       "      <th>a_bbox</th>\n",
       "      <th>o_bbox</th>\n",
       "      <th>area</th>\n",
       "      <th>img_id</th>\n",
       "      <th>labels</th>\n",
       "      <th>duration</th>\n",
       "      <th>rel_position</th>\n",
       "      <th>rel_position_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>[1466.0, 338.0, 1467.0, 413.0]</td>\n",
       "      <td>[1467.0, 413.0, 1467.0, 338.0, 1466.0, 338.0, ...</td>\n",
       "      <td>152</td>\n",
       "      <td>1180</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>102</td>\n",
       "      <td>[1500.0, 211.0, 1520.0, 228.0]</td>\n",
       "      <td>[1522.0, 224.00001525878906, 1517.0, 209.00001...</td>\n",
       "      <td>271</td>\n",
       "      <td>1180</td>\n",
       "      <td>37.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103</td>\n",
       "      <td>[1500.0, 318.0, 1520.0, 335.0]</td>\n",
       "      <td>[1523.0, 325.0, 1512.0, 314.0, 1497.5, 328.5, ...</td>\n",
       "      <td>275</td>\n",
       "      <td>1180</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104</td>\n",
       "      <td>[1519.0, 136.0, 1520.0, 217.0]</td>\n",
       "      <td>[1520.0, 217.0, 1520.0, 136.0, 1519.0, 136.0, ...</td>\n",
       "      <td>164</td>\n",
       "      <td>1180</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ann_id                          a_bbox  \\\n",
       "100     101  [1466.0, 338.0, 1467.0, 413.0]   \n",
       "101     102  [1500.0, 211.0, 1520.0, 228.0]   \n",
       "102     103  [1500.0, 318.0, 1520.0, 335.0]   \n",
       "103     104  [1519.0, 136.0, 1520.0, 217.0]   \n",
       "\n",
       "                                                o_bbox  area  img_id  labels  \\\n",
       "100  [1467.0, 413.0, 1467.0, 338.0, 1466.0, 338.0, ...   152    1180    52.0   \n",
       "101  [1522.0, 224.00001525878906, 1517.0, 209.00001...   271    1180    37.0   \n",
       "102  [1523.0, 325.0, 1512.0, 314.0, 1497.5, 328.5, ...   275    1180    35.0   \n",
       "103  [1520.0, 217.0, 1520.0, 136.0, 1519.0, 136.0, ...   164    1180    52.0   \n",
       "\n",
       "     duration  rel_position  rel_position_mask  \n",
       "100       0.0          50.0                  0  \n",
       "101       8.0          -3.0                  1  \n",
       "102       8.0           4.0                  1  \n",
       "103       0.0          50.0                  0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remap the class labels\n",
    "class_mapping = dict(zip(test_labels['old_id'], test_labels['labels']))\n",
    "\n",
    "# Define a function to replace each cat_id list with corresponding class names\n",
    "def map_cat_ids_to_classes(cat_ids):\n",
    "    return list(set([class_mapping.get(str(cat_id)) for cat_id in cat_ids]))[0]\n",
    "\n",
    "# Apply this function to the cat_id column in train and test obboxs DataFrames\n",
    "train_obboxs['labels'] = train_obboxs['cat_id'].apply(map_cat_ids_to_classes)\n",
    "test_obboxs['labels'] = test_obboxs['cat_id'].apply(map_cat_ids_to_classes)\n",
    "\n",
    "# Function to extract duration and relative position from comments\n",
    "def extract_info(comment):\n",
    "    duration = re.search(r'duration:(\\d+);', comment)\n",
    "    rel_position = re.search(r'rel_position:(-?\\d+);', comment)\n",
    "    return [int(duration.group(1)) if duration else None, int(rel_position.group(1)) if rel_position else None]\n",
    "    \n",
    "# Apply the function to create new columns\n",
    "train_obboxs[['duration', 'rel_position']] = train_obboxs['comments'].apply(extract_info).tolist()\n",
    "test_obboxs[['duration', 'rel_position']] = test_obboxs['comments'].apply(extract_info).tolist()\n",
    "# set items with no duration to 0\n",
    "train_obboxs['duration'] = train_obboxs['duration'].replace(np.nan,0)\n",
    "test_obboxs['duration'] = test_obboxs['duration'].replace(np.nan,0)\n",
    "# create a mask for the rel_position to mark where the rel_position is relevent\n",
    "train_obboxs['rel_position_mask'] = train_obboxs['rel_position'].notna().astype(int)\n",
    "test_obboxs['rel_position_mask'] = test_obboxs['rel_position'].notna().astype(int)\n",
    "# set items with no rel_position to 50 (nothing has a position this high)\n",
    "# we may need to reapproach this with a KNN inference\n",
    "train_obboxs['rel_position'] = train_obboxs['rel_position'].replace(np.nan,50)\n",
    "test_obboxs['rel_position'] = test_obboxs['rel_position'].replace(np.nan,50)\n",
    "\n",
    "# clean up\n",
    "train_obboxs.reset_index(inplace=True)\n",
    "test_obboxs.reset_index(inplace=True)\n",
    "train_obboxs.drop(['cat_id','comments'], axis=1, inplace=True)\n",
    "test_obboxs.drop(['cat_id','comments'], axis=1, inplace=True)\n",
    "train_obboxs.rename(columns={'index': 'ann_id'}, inplace=True)\n",
    "test_obboxs.rename(columns={'index': 'ann_id'}, inplace=True)\n",
    "train_obboxs['ann_id'] = train_obboxs['ann_id'].astype(int)\n",
    "test_obboxs['ann_id'] = test_obboxs['ann_id'].astype(int)\n",
    "train_obboxs['area'] = train_obboxs['area'].astype(int)\n",
    "test_obboxs['area'] = test_obboxs['area'].astype(int)\n",
    "train_obboxs['img_id'] = train_obboxs['img_id'].astype(int)\n",
    "test_obboxs['img_id'] = test_obboxs['img_id'].astype(int)\n",
    "test_obboxs.iloc[100:104]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f222b0bf-65dc-4845-978c-5ec7174949f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fb5e82f-5bb7-4c29-ab8b-4ef432f79e28",
   "metadata": {},
   "source": [
    "## join the tables together to get one big table with the complete info for every annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2521e38d-4dc1-4172-ada5-7a27aa292d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann_id</th>\n",
       "      <th>a_bbox</th>\n",
       "      <th>o_bbox</th>\n",
       "      <th>area</th>\n",
       "      <th>img_id</th>\n",
       "      <th>labels</th>\n",
       "      <th>duration</th>\n",
       "      <th>rel_position</th>\n",
       "      <th>rel_position_mask</th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1020</td>\n",
       "      <td>[116.0, 139.0, 2315.0, 206.0]</td>\n",
       "      <td>[2315.0, 206.0, 2315.0, 139.0, 116.0, 139.0, 1...</td>\n",
       "      <td>18945</td>\n",
       "      <td>679</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>lg-877777775968732096-aug-gonville--page-3.png</td>\n",
       "      <td>2431</td>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>[116.0, 309.0, 2315.0, 376.0]</td>\n",
       "      <td>[2315.0, 376.0, 2315.0, 309.0, 116.0, 309.0, 1...</td>\n",
       "      <td>19223</td>\n",
       "      <td>679</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>lg-877777775968732096-aug-gonville--page-3.png</td>\n",
       "      <td>2431</td>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1022</td>\n",
       "      <td>[1880.0, 561.0, 1911.0, 564.0]</td>\n",
       "      <td>[1911.0, 564.0, 1911.0, 561.0, 1880.0, 561.0, ...</td>\n",
       "      <td>120</td>\n",
       "      <td>679</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>lg-877777775968732096-aug-gonville--page-3.png</td>\n",
       "      <td>2431</td>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1023</td>\n",
       "      <td>[1883.0, 578.0, 1911.0, 580.0]</td>\n",
       "      <td>[1911.0, 580.0, 1911.0, 578.0, 1883.0, 578.0, ...</td>\n",
       "      <td>27</td>\n",
       "      <td>679</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>lg-877777775968732096-aug-gonville--page-3.png</td>\n",
       "      <td>2431</td>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ann_id                          a_bbox  \\\n",
       "0    1020   [116.0, 139.0, 2315.0, 206.0]   \n",
       "1    1021   [116.0, 309.0, 2315.0, 376.0]   \n",
       "2    1022  [1880.0, 561.0, 1911.0, 564.0]   \n",
       "3    1023  [1883.0, 578.0, 1911.0, 580.0]   \n",
       "\n",
       "                                              o_bbox   area  img_id  labels  \\\n",
       "0  [2315.0, 206.0, 2315.0, 139.0, 116.0, 139.0, 1...  18945     679   165.0   \n",
       "1  [2315.0, 376.0, 2315.0, 309.0, 116.0, 309.0, 1...  19223     679   165.0   \n",
       "2  [1911.0, 564.0, 1911.0, 561.0, 1880.0, 561.0, ...    120     679     2.0   \n",
       "3  [1911.0, 580.0, 1911.0, 578.0, 1883.0, 578.0, ...     27     679     2.0   \n",
       "\n",
       "   duration  rel_position  rel_position_mask  \\\n",
       "0       0.0          50.0                  0   \n",
       "1       0.0          50.0                  0   \n",
       "2       0.0          50.0                  0   \n",
       "3       0.0          50.0                  0   \n",
       "\n",
       "                                         filename  width  height  \n",
       "0  lg-877777775968732096-aug-gonville--page-3.png   2431    3439  \n",
       "1  lg-877777775968732096-aug-gonville--page-3.png   2431    3439  \n",
       "2  lg-877777775968732096-aug-gonville--page-3.png   2431    3439  \n",
       "3  lg-877777775968732096-aug-gonville--page-3.png   2431    3439  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.merge(train_obboxs, train_images, on='img_id', how='inner')\n",
    "test_data = pd.merge(test_obboxs, test_images, on='img_id', how='inner')\n",
    "train_data.drop('ann_ids', axis=1, inplace=True)\n",
    "test_data.drop('ann_ids', axis=1, inplace=True)\n",
    "train_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b35dd-e480-48aa-9f00-e2b97d0d2608",
   "metadata": {},
   "source": [
    "### compute the yolo bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd6d941f-8997-4a8b-aed4-1e7dc590ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corners_to_yolo(bbox, img_width, img_height):\n",
    "    polygon = Polygon([(bbox[i], bbox[i + 1]) for i in range(0, len(bbox), 2)])\n",
    "    min_rect = polygon.minimum_rotated_rectangle\n",
    "\n",
    "    # Check if the minimum rotated rectangle is a point\n",
    "    if isinstance(min_rect, Point):\n",
    "        # Handle the case where the shape is a point by creating a small box around it\n",
    "        x, y = min_rect.x, min_rect.y\n",
    "        min_rect = Polygon([(x-1, y-1), (x+1, y-1), (x+1, y+1), (x-1, y+1)])\n",
    "        return 'invalid'\n",
    "\n",
    "    # check if symbol is a line and add 1 px padding if so (almost always stems)\n",
    "    elif isinstance(min_rect, LineString):\n",
    "        # Handle the case where the shape is a line by padding\n",
    "        x_coords, y_coords = zip(*min_rect.coords)\n",
    "        min_x, max_x = min(x_coords), max(x_coords)\n",
    "        min_y, max_y = min(y_coords), max(y_coords)\n",
    "        min_rect = Polygon([(min_x-1, min_y-1), (max_x+1, min_y-1), (max_x+1, max_y+1), (min_x-1, max_y+1)])\n",
    "\n",
    "    corners = np.array(min_rect.exterior.coords)\n",
    "    edge1 = np.linalg.norm(corners[0] - corners[1])\n",
    "    edge2 = np.linalg.norm(corners[1] - corners[2])\n",
    "    width = max(edge1, edge2)\n",
    "    height = min(edge1, edge2)\n",
    "    center = min_rect.centroid.coords[0]\n",
    "    center_x = center[0]\n",
    "    center_y = center[1]\n",
    "    angle = np.rad2deg(np.arctan2(corners[1][1] - corners[0][1], corners[1][0] - corners[0][0]))\n",
    "\n",
    "    center_x /= img_width\n",
    "    center_y /= img_height\n",
    "    width /= img_width\n",
    "    height /= img_height\n",
    "\n",
    "    return [center_x, center_y, width, height, angle]\n",
    "    \n",
    "# Function to convert corners to YOLO format for each row in the DataFrame\n",
    "def apply_corners_to_yolo(row):\n",
    "    return corners_to_yolo(row['o_bbox'], row['width'], row['height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d35fd744-0634-4b48-b2b9-7c2d44c4cb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann_id</th>\n",
       "      <th>a_bbox</th>\n",
       "      <th>o_bbox</th>\n",
       "      <th>area</th>\n",
       "      <th>img_id</th>\n",
       "      <th>labels</th>\n",
       "      <th>duration</th>\n",
       "      <th>rel_position</th>\n",
       "      <th>rel_position_mask</th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>yolo_bbox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1020</td>\n",
       "      <td>[116.0, 139.0, 2315.0, 206.0]</td>\n",
       "      <td>[2315.0, 206.0, 2315.0, 139.0, 116.0, 139.0, 1...</td>\n",
       "      <td>18945</td>\n",
       "      <td>679</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>lg-877777775968732096-aug-gonville--page-3.png</td>\n",
       "      <td>2431</td>\n",
       "      <td>3439</td>\n",
       "      <td>[0.5, 0.05015993021227101, 0.904566022213081, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ann_id                         a_bbox  \\\n",
       "0    1020  [116.0, 139.0, 2315.0, 206.0]   \n",
       "\n",
       "                                              o_bbox   area  img_id  labels  \\\n",
       "0  [2315.0, 206.0, 2315.0, 139.0, 116.0, 139.0, 1...  18945     679   165.0   \n",
       "\n",
       "   duration  rel_position  rel_position_mask  \\\n",
       "0       0.0          50.0                  0   \n",
       "\n",
       "                                         filename  width  height  \\\n",
       "0  lg-877777775968732096-aug-gonville--page-3.png   2431    3439   \n",
       "\n",
       "                                           yolo_bbox  \n",
       "0  [0.5, 0.05015993021227101, 0.904566022213081, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column with bounding boxes in (center x, center y, W, H, R)*normalized format\n",
    "train_data['yolo_bbox'] = train_data.apply(apply_corners_to_yolo, axis=1)\n",
    "test_data['yolo_bbox'] = test_data.apply(apply_corners_to_yolo, axis=1)\n",
    "# drop invalid boxes\n",
    "train_data = train_data[train_data['yolo_bbox']!='invalid']\n",
    "test_data = test_data[test_data['yolo_bbox']!='invalid']\n",
    "train_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd4716b1-e04d-4134-867b-d33d4964d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_agg = train_data.groupby('filename').agg({\n",
    "    'ann_id': lambda x: list(x),\n",
    "    'a_bbox': lambda x: list(x),\n",
    "    'o_bbox': lambda x: list(x),\n",
    "    'area': lambda x: list(x),\n",
    "    'duration': lambda x: list(x),\n",
    "    'rel_position': lambda x: list(x), \n",
    "    'labels': lambda x: list(x),\n",
    "    'img_id': 'first',  # assuming all entries per image have the same img_id\n",
    "    'width': 'first',   # assuming all entries per image have the same width\n",
    "    'height': 'first'  # assuming all entries per image have the same height\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1c4a66e-096d-44d0-8841-106da6c3169a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>a_bbox</th>\n",
       "      <th>o_bbox</th>\n",
       "      <th>area</th>\n",
       "      <th>duration</th>\n",
       "      <th>rel_position</th>\n",
       "      <th>labels</th>\n",
       "      <th>img_id</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lg-101766503886095953-aug-beethoven--page-1.png</td>\n",
       "      <td>[632316, 632317, 632318, 632319, 632320, 63232...</td>\n",
       "      <td>[[233.0, 376.0, 1866.0, 443.0], [233.0, 833.0,...</td>\n",
       "      <td>[[1866.0, 443.0, 1866.0, 376.0, 233.0, 376.0, ...</td>\n",
       "      <td>[13425, 9986, 73, 75, 12613, 10958, 105, 269, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, ...</td>\n",
       "      <td>[50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, -2....</td>\n",
       "      <td>[165.0, 165.0, 2.0, 2.0, 165.0, 165.0, 52.0, 3...</td>\n",
       "      <td>142</td>\n",
       "      <td>1960</td>\n",
       "      <td>2772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          filename  \\\n",
       "0  lg-101766503886095953-aug-beethoven--page-1.png   \n",
       "\n",
       "                                              ann_id  \\\n",
       "0  [632316, 632317, 632318, 632319, 632320, 63232...   \n",
       "\n",
       "                                              a_bbox  \\\n",
       "0  [[233.0, 376.0, 1866.0, 443.0], [233.0, 833.0,...   \n",
       "\n",
       "                                              o_bbox  \\\n",
       "0  [[1866.0, 443.0, 1866.0, 376.0, 233.0, 376.0, ...   \n",
       "\n",
       "                                                area  \\\n",
       "0  [13425, 9986, 73, 75, 12613, 10958, 105, 269, ...   \n",
       "\n",
       "                                            duration  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, ...   \n",
       "\n",
       "                                        rel_position  \\\n",
       "0  [50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, -2....   \n",
       "\n",
       "                                              labels  img_id  width  height  \n",
       "0  [165.0, 165.0, 2.0, 2.0, 165.0, 165.0, 52.0, 3...     142   1960    2772  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_agg.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf07070-946c-4a2d-90fc-dadce3aabf72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e81a6b5-27af-44e4-9646-5805bfcb83e1",
   "metadata": {},
   "source": [
    "## Prepare the Torch dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c39ab1a4-ad58-4428-b4dd-2d3bd4dd7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicScoreDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (DataFrame): Pandas DataFrame containing annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transforms (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.annotations = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        # Set default transforms if none are provided\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),  # Convert images to tensors\n",
    "                # transforms.Normalize(mean=[0.485], std=[0.229])  # Adjust if your image is not RGB\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.annotations['filename'].iloc[idx])\n",
    "        image = Image.open(img_name).convert(\"L\") # use grayscale\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        boxes = torch.as_tensor(self.annotations['a_bbox'].iloc[idx], dtype=torch.float32)\n",
    "        durations = torch.as_tensor(self.annotations['duration'].iloc[idx], dtype=torch.float32)\n",
    "        rel_positions = torch.as_tensor(self.annotations['rel_position'].iloc[idx], dtype=torch.float32)\n",
    "        labels = torch.as_tensor(self.annotations['labels'].iloc[idx], dtype=torch.int64)\n",
    "        image_id = torch.tensor([self.annotations['img_id'].iloc[idx]], dtype=torch.int64)\n",
    "        area = torch.as_tensor([self.annotations['area'].iloc[idx]], dtype=torch.float32)\n",
    "        iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)  # Assuming no crowd\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"durations\"] = durations\n",
    "        target[\"rel_positions\"] = rel_positions\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2fec48e-587a-4bf5-af96-7c6d74aaf575",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MusicScoreDataset(train_data_agg, './data/ds2_dense/images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eef7b9b0-6a41-46d4-9536-d020c5ac9246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]]]),\n",
       " {'boxes': tensor([[ 233.,  376., 1866.,  443.],\n",
       "          [ 233.,  833., 1866.,  899.],\n",
       "          [1633.,  587., 1666.,  589.],\n",
       "          ...,\n",
       "          [ 732., 2267.,  752., 2284.],\n",
       "          [ 751., 2187.,  752., 2272.],\n",
       "          [ 752., 2188.,  769., 2234.]]),\n",
       "  'labels': tensor([165, 165,   2,   2, 165, 165,  52,  35, 100,  37,  52,  41,  42,  35,\n",
       "           52,  52,  52,  35,  37,  37,  35,  58,  52,  52, 146,  52,  52,  35,\n",
       "           37,  37,  37,  58,  52, 100,  37,  52,  37,  35,  35,  37,  52, 100,\n",
       "           37,  58,  52, 146,  58,  52,  42,  37,  58,  52,  37,  35,  35, 100,\n",
       "          100,  99,  58,  52,  52,  37,  35,  35,  35,  52,  37,  52,  52,  41,\n",
       "          100,  99,  58,  52,  35,  35,  35,  41,  58,  52,  35,  35,  35,  58,\n",
       "           52,  35,  35,  52,  52,  41, 100,  80,  80,  80,  80,  10, 100,  25,\n",
       "           25,  80,  80,  80,  80,  13,  41,  25,  25,  80,  80,  80,  80,  10,\n",
       "           98,  25,  25,   1,  52,  35,  52,  25,  25,  80,  80,  80,  80,  13,\n",
       "           41,  58,  52,  35,  37,  37,  52,  37,  52,  42, 100,  41,  37,  58,\n",
       "           52,  35,  37, 100,  99,  52,  42, 100,  41,  35,  58,  52,  35,  35,\n",
       "           35, 100,  37,  52,  52, 165,   2,   2, 165, 165,   2,   2,   2, 165,\n",
       "           52,  37,  37,  37,  52,  52,  41, 100,  41,  35, 100,  37,  37,  35,\n",
       "           52,  52,  35,  35,  58,  52,  37,  52,  52,  52, 146,  37,  37,  37,\n",
       "           35,  52,  52,  58,  52, 100,  35,  58,  52,  35,  37,  37,  35,  52,\n",
       "           35,  37,  52,  58, 100,  52,  52,  42, 100,  42,  41,  58, 146,  52,\n",
       "           58,  52,  37,  35,  35,  52,  52,  52,  42, 100,  42,  37,  58,  58,\n",
       "           37,  35,  35,  52, 100,  37,  52,  52,  37,  35,  35,  52,  99,  42,\n",
       "          100,  42, 100,  52,  35,  37,  37,  52,  58,  37,  35,  35,  37,  64,\n",
       "           52,  99, 100, 100,  58,  52,  37,  37,  35,  10,  10,  80,  80,  80,\n",
       "           80,  13,  80,  80,  80,  80,  80,  80,  80,  80,  13,  80,  80,  80,\n",
       "           80,   1,  35,  52,  37,  37,  52,  58,  52,  52,  52,  42, 100,  42,\n",
       "           37,  41,  41, 100,  41,  52,  58,  52,  52,  35,  35,  35,  58,  52,\n",
       "          100,  37,  41, 100,  41,  99,  58,  52,  35,  35,  35, 100,  58,  52,\n",
       "           35,  35,  35,  52,  52,  52,  52,   8,  41, 100,  41,  37,  35,  35,\n",
       "           35,  52,  58]),\n",
       "  'durations': tensor([0., 0., 0., 0., 0., 0., 0., 8., 0., 4., 0., 2., 2., 8., 0., 0., 0., 8.,\n",
       "          8., 8., 8., 0., 0., 0., 0., 0., 0., 8., 8., 8., 8., 0., 0., 0., 8., 0.,\n",
       "          8., 8., 8., 8., 0., 0., 8., 0., 0., 0., 0., 0., 2., 8., 0., 0., 8., 8.,\n",
       "          8., 0., 0., 0., 0., 0., 0., 8., 8., 8., 8., 0., 8., 0., 0., 2., 0., 0.,\n",
       "          0., 0., 8., 8., 8., 2., 0., 0., 8., 8., 8., 0., 0., 8., 8., 0., 0., 2.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 8., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          2., 0., 0., 8., 8., 8., 0., 8., 0., 2., 0., 2., 8., 0., 0., 8., 8., 0.,\n",
       "          0., 0., 2., 0., 2., 4., 0., 0., 8., 8., 8., 0., 4., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 8., 8., 8., 0., 0., 2., 0., 2., 8., 0., 8.,\n",
       "          8., 8., 0., 0., 8., 8., 0., 0., 8., 0., 0., 0., 0., 8., 8., 8., 8., 0.,\n",
       "          0., 0., 0., 0., 8., 0., 0., 8., 8., 8., 8., 0., 8., 8., 0., 0., 0., 0.,\n",
       "          0., 2., 0., 2., 2., 0., 0., 0., 0., 0., 8., 8., 8., 0., 0., 0., 2., 0.,\n",
       "          2., 4., 0., 0., 8., 8., 8., 0., 0., 4., 0., 0., 8., 8., 8., 0., 0., 2.,\n",
       "          0., 2., 0., 0., 8., 8., 8., 0., 0., 8., 8., 8., 8., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 8., 8., 8., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 8., 0., 8., 8., 0., 0., 0., 0., 0., 2.,\n",
       "          0., 2., 4., 2., 2., 0., 2., 0., 0., 0., 0., 8., 8., 8., 0., 0., 0., 4.,\n",
       "          2., 0., 2., 0., 0., 0., 8., 8., 8., 0., 0., 0., 8., 8., 8., 0., 0., 0.,\n",
       "          0., 0., 2., 0., 2., 4., 8., 8., 8., 0., 0.]),\n",
       "  'rel_positions': tensor([50., 50., 50., 50., 50., 50., 50., -2., 50.,  1., 50., -1.,  6., -4.,\n",
       "          50., 50., 50.,  0., -3., -5.,  4., 50., 50., 50., 50., 50., 50.,  0.,\n",
       "          -3., -5.,  3., 50., 50., 50.,  5., 50.,  1., -2., -4.,  3., 50., 50.,\n",
       "           5., 50., 50., 50., 50., 50.,  6.,  3., 50., 50.,  1., -2., -4., 50.,\n",
       "          50., 50., 50., 50., 50.,  1., -2., -4.,  4., 50.,  1., 50., 50., -1.,\n",
       "          50., 50., 50., 50.,  0., -2., -4.,  1., 50., 50.,  0., -2., -4., 50.,\n",
       "          50.,  0., -2., 50., 50.,  3., 50., 50., 50., 50., 50., 50., 50., 50.,\n",
       "          50., 50., 50., 50., 50., 50.,  1., 50., 50., 50., 50., 50., 50., 50.,\n",
       "          50., 50., 50., 50., 50., -4., 50., 50., 50., 50., 50., 50., 50., 50.,\n",
       "           3., 50., 50.,  0., -3., -5., 50., -3., 50., -2., 50.,  5.,  3., 50.,\n",
       "          50.,  0., -5., 50., 50., 50.,  2., 50.,  5.,  4., 50., 50.,  0., -2.,\n",
       "          -4., 50.,  5., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50.,\n",
       "          50.,  5., -5., -3., 50., 50.,  5., 50.,  5.,  6., 50., -5., -3.,  0.,\n",
       "          50., 50.,  0.,  4., 50., 50.,  3., 50., 50., 50., 50.,  5., -5., -3.,\n",
       "           0., 50., 50., 50., 50., 50.,  4., 50., 50.,  0., -3., -5., -4., 50.,\n",
       "          -2.,  1., 50., 50., 50., 50., 50.,  6., 50.,  6.,  5., 50., 50., 50.,\n",
       "          50., 50.,  1., -2., -4., 50., 50., 50.,  6., 50.,  6.,  5., 50., 50.,\n",
       "           1., -2., -4., 50., 50.,  5., 50., 50.,  1., -2., -4., 50., 50.,  4.,\n",
       "          50.,  4., 50., 50., -4., -1.,  1., 50., 50.,  1.,  0., -4., -1., 50.,\n",
       "          50., 50., 50., 50., 50., 50.,  1., -1., -4., 50., 50., 50., 50., 50.,\n",
       "          50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50.,\n",
       "          50., 50., -4., 50., -1.,  1., 50., 50., 50., 50., 50.,  4., 50.,  4.,\n",
       "           1.,  5.,  1., 50.,  1., 50., 50., 50., 50.,  0., -2., -4., 50., 50.,\n",
       "          50.,  5.,  5., 50.,  5., 50., 50., 50.,  0., -2., -4., 50., 50., 50.,\n",
       "           0., -2., -4., 50., 50., 50., 50., 50.,  1., 50.,  1.,  5., -2.,  0.,\n",
       "          -4., 50., 50.]),\n",
       "  'image_id': tensor([142]),\n",
       "  'area': tensor([[13425.,  9986.,    73.,    75., 12613., 10958.,   105.,   269.,   198.,\n",
       "             281.,   112.,   197.,   209.,   282.,   165.,   141.,    87.,   290.,\n",
       "             282.,   288.,   289.,   143.,   104.,   106.,   987.,   132.,    78.,\n",
       "             292.,   285.,   285.,   290.,   147.,   109.,   203.,   290.,    72.,\n",
       "             273.,   269.,   282.,   287.,   103.,   196.,   286.,   125.,   228.,\n",
       "             993.,   126.,   184.,   204.,   284.,   128.,   148.,   290.,   284.,\n",
       "             288.,   201.,   198.,   326.,   129.,   170.,    93.,   285.,   284.,\n",
       "             283.,   285.,   104.,   288.,   110.,    84.,   210.,   197.,   315.,\n",
       "             127.,   147.,   279.,   286.,   283.,   202.,   126.,   209.,   279.,\n",
       "             285.,   283.,   125.,   146.,   280.,   285.,   102.,   110.,   208.,\n",
       "             198.,   426.,   426.,   428.,   426.,  1635.,   197.,   300.,   290.,\n",
       "             426.,   428.,   428.,   426.,   651.,   201.,   286.,   295.,   429.,\n",
       "             426.,   426.,   428.,  1638.,   189.,   314.,   286.,  1280.,   101.,\n",
       "             284.,   110.,   300.,   290.,   426.,   428.,   428.,   427.,   652.,\n",
       "             207.,   132.,   149.,   290.,   284.,   285.,   105.,   267.,    78.,\n",
       "             209.,   202.,   208.,   290.,   133.,   165.,   288.,   285.,   203.,\n",
       "             317.,   104.,   214.,   202.,   204.,   289.,   125.,   145.,   279.,\n",
       "             286.,   285.,   198.,   279.,   112.,   110., 11575.,    97.,    97.,\n",
       "           15505., 13765.,    49.,    97.,    97., 15504.,   103.,   280.,   277.,\n",
       "             274.,   103.,    86.,   207.,   195.,   207.,   287.,   202.,   274.,\n",
       "             271.,   269.,    72.,    77.,   279.,   287.,   123.,   190.,   285.,\n",
       "              88.,   103.,   103.,   294.,   283.,   275.,   274.,   273.,   104.,\n",
       "             174.,   146.,    87.,   200.,   292.,   120.,   242.,   286.,   278.,\n",
       "             285.,   277.,   103.,   270.,   272.,   167.,   151.,   196.,   103.,\n",
       "             103.,   210.,   196.,   210.,   209.,   136.,   935.,   147.,   135.,\n",
       "             143.,   284.,   280.,   286.,   157.,   157.,   157.,   210.,   199.,\n",
       "             207.,   286.,   133.,   129.,   290.,   283.,   284.,   103.,   196.,\n",
       "             284.,   190.,   151.,   287.,   286.,   289.,   104.,   315.,   209.,\n",
       "             196.,   204.,   196.,   110.,   279.,   268.,   274.,   167.,   150.,\n",
       "             263.,   275.,   279.,   270.,   151.,   167.,   314.,   195.,   200.,\n",
       "             136.,   146.,   284.,   285.,   285.,  1640.,  1633.,   426.,   426.,\n",
       "             429.,   429.,   653.,   431.,   426.,   426.,   428.,   429.,   428.,\n",
       "             426.,   426.,   651.,   429.,   426.,   426.,   428.,  1285.,   284.,\n",
       "             158.,   267.,   273.,   167.,   145.,   159.,   158.,   155.,   208.,\n",
       "             202.,   208.,   287.,   202.,   203.,   199.,   205.,   110.,   135.,\n",
       "             110.,   132.,   278.,   281.,   286.,   151.,   103.,   195.,   290.,\n",
       "             209.,   196.,   208.,   318.,   123.,   146.,   283.,   280.,   291.,\n",
       "             202.,   124.,   213.,   281.,   280.,   287.,   110.,   103.,   103.,\n",
       "             103.,  1188.,   208.,   197.,   208.,   285.,   262.,   269.,   279.,\n",
       "             156.,   149.]]),\n",
       "  'iscrowd': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1d71b0-2cf5-4543-9044-6a10d09dbbcc",
   "metadata": {},
   "source": [
    "## prepare the model- we will use faster r-cnn resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a18062b-ebce-46da-8b2f-5396d73fac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    # Load a model pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    \n",
    "    # Replace the classifier with a new one, that has\n",
    "    # num_classes which is user-defined\n",
    "    num_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(num_features, num_classes)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82095ce-0d98-43cd-b400-76fc030056f4",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "287bd6d5-8e4d-4855-8b97-51889963add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    # note there is no loss function defined because the model deos it for us\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, targets in data_loader:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1} of {num_epochs}, Loss: {losses.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c192bf08-479c-4377-872c-9b35223d747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "num_classes = len(unique_labels) + 1  # Define the number of classes including background\n",
    "model = get_model(num_classes).to(device)\n",
    "data_loader = DataLoader(MusicScoreDataset(train_data_agg, './data/ds2_dense/images/'), batch_size=2, shuffle=True)\n",
    "optimizer = SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e345793-7394-485d-aea3-bc3ed5401080",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [458, 4] at entry 0 and [564, 4] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_model(model, data_loader, optimizer)\n",
      "Cell \u001b[0;32mIn[44], line 5\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, data_loader, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# note there is no loss function defined because the model deos it for us\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, targets \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m      6\u001b[0m         images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(image\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images)\n\u001b[1;32m      7\u001b[0m         targets \u001b[38;5;241m=\u001b[39m [{k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m targets]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[38;5;241m=\u001b[39mdefault_collate_fn_map)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:129\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:129\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(batch, \u001b[38;5;241m0\u001b[39m, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [458, 4] at entry 0 and [564, 4] at entry 1"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "train_model(model, data_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ba4697-8f86-4ce2-b5f5-92a81089060c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c7c0cd-d79b-40bd-9530-5b736181cb43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27a7e72-beeb-4a10-b44d-0b51f335d443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
